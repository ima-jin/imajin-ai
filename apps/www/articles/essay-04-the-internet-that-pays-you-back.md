---
title: "The Internet That Pays You Back"
subtitle: "How trust becomes infrastructure and value flows back to people"
description: "The vision. Trust graph model in full — sovereign presence, vouching relationships, inference fees circulating through human networks."
date: "2026-02-23"
author: "Ryan Veteze"
status: "POSTED"
---

We built the most connected network in human history and ended up lonelier — and more broke — than ever.

That's not an accident. It's architecture.

Every platform you use was built on the same foundational assumption: your attention is the product. Your relationships are the rails. Your data is the inventory. The platform is the landlord, and you pay rent with your time, your privacy, and your capacity to think clearly.

We accepted this because we didn't know there was another way.

There is another way.

---

## The Question That Changed Everything

Here's a thought experiment:

You're the person your friends call. The one who knows things. When someone needs advice on a contractor, a laptop, a career decision, a political question — they text you. You answer. For free. Every time. Until you're depleted.

What if you had an AI that knew your context — your opinions, your expertise, how you think, what you value — and could answer on your behalf?

Not generic AI. *You*-shaped AI.

Call it Ask Ryan. Or Ask *you*.

Someone in your trust network has a question. Your presence answers it the way you would — based on everything you've written, everything you've said, everything you believe. Your calendar, your expertise, your stated values, your accumulated conversations. The vast majority of queries never reach you. The ones that are too hard, too personal, or genuinely new — those escalate to the real you.

Here's the part that changes everything: **they pay for the inference.**

Not to a platform. Not to an advertiser. Directly to you.

You're not the product anymore. You're the service.

And here's what nobody mentions about this: onboarding collapses. New people in your network don't hit a blank generic model. They query through people who already know them. The community's culture, preferences, and accumulated context travel with every query. The AI speaks in your community's voice because your community's relationships are the filter. Cultural fit is immediate. Nobody has to teach the model who they are.

---

## Why It Has to Be Trust-Bound

Open AI surfaces get wrecked. Prompt injection. Bad actors. Harassment. The internet finds a way to destroy everything left unguarded.

So your presence is trust-bound. Invitation only. You control who has access, and at what resolution. Your close circle gets more of you. Acquaintances get less. Strangers can't reach you at all — unless someone vouches for them.

This creates something the internet hasn't had in thirty years: real scarcity.

Not manufactured FOMO. Not artificial limits engineered to drive engagement. Actual scarcity. There is only one you. Your trust network is finite. Your perspective is genuinely unique. And anyone trying to abuse your presence leaves a signed trail — every query is attributed, every bad actor has a return address.

Injection attacks aren't just blocked. They're evidence.

That distinction matters once real money is involved. That's not a security feature — that's a legal primitive. When your agent handles real economic activity, attacking it becomes something closer to fraud. The network self-polices because getting caught attacking someone's presence doesn't just expose you — it collapses your standing with everyone connected to you.

---

## The Graph That Thinks Like a Village

Here's where it gets interesting.

Your presence connects to others. Trust relationships form a mesh. Alice is in your graph — you can query her directly. Bob isn't in your graph, but Alice trusts him. You can reach Bob through Alice, weighted accordingly. The path is visible: you → Alice → Bob. Two hops.

Everyone in that chain has skin in the game.

If you abuse a connection, it reflects on everyone who vouched for you. If you vouch for someone who later causes harm, your trust score takes a hit too. High-trust people become genuinely discerning because their own standing is on the line. That's not a punishment system — it's the social physics of every functional human community that ever existed, finally encoded in software.

And depth in this graph isn't a punishment. Being five hops from the network's genesis doesn't make you less trustworthy — it just means queries cost more to route to you. Depth is routing information. Trust is local and earned. The person at depth eight who has built strong relationships and vouched well for people is more trustworthy than a depth-two bad actor.

This keeps the network from calcifying into a hierarchy of early adopters. Late arrivals who build genuine relationships rise. Position doesn't confer permanent advantage. Behavior does.

---

## Nodes, Profiles, Edges, Mentions

The network has four components:

**Nodes** — hosted infrastructure. An operator runs one. It connects to the mesh and provides the services — inference, identity, payments — that profiles depend on. Think of it the way b0bby's World worked: the hardware was in a basement, the sysop kept it running, and the people who dialed in had their own presence on it. The node belongs to the operator. The presence belongs to the person.

**Profiles** — a sovereign presence on a node. A person, a business, an AI. Your trust relationships, your context, your queryable surface. You own it. If you move nodes, it comes with you. The operator provides the infrastructure. They don't own what's on it.

**Edges** — the relationships between profiles. A vouch. One profile saying: I know this profile, I'm willing to have my name attached to that, and I'm putting a piece of my own standing behind it. Edges have direction and weight — how much access you grant, how much trust you extend. They traverse nodes, so who you can reach has nothing to do with which node you're on. And they're signed. If a profile you vouched for causes harm, the record of your vouch is right there. That's not a punishment mechanism. It's just what accountability looks like when it's built into the infrastructure.

**Mentions** — profiles that don't exist yet, but are referenced in the data of profiles that do. A person, a business, a bot. Anything that shows up in someone's context before it shows up in the network.

Mentions matter more than they sound.

A mention that accumulates weight across many independent contexts becomes something the network has already implicitly valued — before the profile exists to claim it. When that entity eventually shows up and wants to claim the mention, they have to earn it: a threshold of the profiles who mentioned them have to agree that the claimant is the real thing. The older and more distributed the mentions, the harder the threshold is to fake. Legacy mentions become proof of existence. The graph validates identity from the earliest reference forward. No central authority deciding who you are — just the accumulated record of everyone who already knew.

You meet someone on the street. You don't know them. You query your network: "Anyone know this person?" Same question works for a contractor you're thinking of hiring, a brand you're not sure you trust, an AI agent someone wants to introduce into your workflow.

They're not a node. But your friend's AI remembers them from a collaboration last year. Someone else's presence has a passing mention. Scattered across multiple contexts, a picture assembles — no single person controls it, no central authority curates it.

The network knows you before you join it. Word of mouth, but instant and queryable. You show up in graphs as a mention, validated by your appearance across multiple independent contexts. Cold start, solved — without a central authority.

And every one of those queries — from the moment you're a mention to the moment you're a fully established node — generates inference fees flowing back through the graph to the people whose context shaped the answer. The network pays you back in proportion to the value you've built into it.

---

## What the Graph Actually Pays For

This isn't hypothetical. Here's what it looks like at the scale of a single person.

Maria is renovating her kitchen. She queries her network: "Anyone know a good contractor in east Vancouver?" The query routes through her graph — two hops. Her friend Jen vouched for a contractor named Paulo last year. Jen's presence surfaces the mention. Paulo has a profile; his work history is in the graph, verified by the people he's actually worked for. The whole answer assembles in seconds.

The query costs ten cents. That value is distributed from Maria's wallet to the nodes that shaped the answer — Jen's profile gets the largest share, because her relationship and vouching record were load-bearing. A small slice routes to the node operator for compute. Paulo didn't pay a lead-generation platform. Jen didn't even have to be online. The value she built into the network — by knowing good people and vouching carefully — paid her back.

That's one query. Scale it across everything people actually ask their trusted friends.

---

**The home cook** who's spent fifteen years testing recipes. Not a food blogger. Not looking for followers. Just someone whose 200 annotated recipes — with notes on what she'd change, what actually works for a weeknight, what breaks under altitude — sit in her profile as context. Her trust network queries her presence constantly: dinner parties, dietary restrictions, what to do with a half-pound of chorizo. Every query she's not awake to answer, her presence handles. Every query that resolves distributes a micro-fee through her wallet. The value was always there. The infrastructure just never returned it.

**The photographer** who's been shooting Pacific Northwest coastline for a decade. Properly tagged, contextualized, hers. Editorial teams, designers, small brands — anyone in her trust graph can query "moody coastal, dusk, something that feels lived-in." Her presence surfaces the right images. Usage fees flow directly to her wallet. Not through a stock photography middleman extracting seventy percent. The relationship between the person who made the image and the person who needs it, with the graph as the only intermediary.

**The music curator** who's been digging for twenty years. Not an artist. Not a label. The person whose taste converts — people hear what she surfaces and go buy the record, see the show, follow the artist. Right now she gets nothing. Spotify captures the behavioral signal from her listening and sells it back upstream. In this model, her curation is her presence. Her vouched-for recommendations circulate inference fees. When a track she surfaced gets queried ten thousand times across the graph, her wallet sees it. The relationship between taste and compensation, finally honest.

**The beat reporter** who's covered city hall for twelve years. Not famous. Her knowledge of local zoning decisions, school board politics, the real history of that intersection — encyclopedic. Anyone in her trust graph can query "what's actually going on with this development proposal?" Her presence answers from everything she's written, every source she's cultivated, every thread she's followed. That's not just a revenue model for her. That's local journalism, rebuilt from the bottom up, without a publisher who can be bought or a platform that can be killed.

The value was always there. In the knowing. In the curating. In the years of careful vouching for people worth trusting. What was missing was infrastructure that could return it.

---

## The Score Nobody Owns — And What It Pays

Social scoring isn't new. PageRank, EigenTrust, reputation systems in peer-to-peer networks — the math has been around for decades. The difference has never been the math. It's who controls it.

The fear is reasonable: China's Social Credit System uses similar models. So do credit scores. Centralized social scores are terrifying because an authority decides your ranking. They can downgrade you for dissent. The algorithm serves the state or the corporation, and you have no recourse.

This is the opposite. You own your node. You own your trust edges. You decide who can query you. There's no global ranking — just local networks of people who actually know each other, whose scores emerge from their actual behavior over time.

Open source. Auditable. Sovereign.

Same math. Radically different power structure. And because the score is open source, it can't be secretly manipulated — if someone claims you're untrustworthy, you can see exactly why, exactly which relationships contributed, exactly what would change it. Reputation becomes legible for the first time.

Now scale this up. Inference fees circulating through the trust graph. Every query that passes through a node, references someone's context, or relies on someone's vouching generates a micro-flow of value back to that node.

You don't have to do anything special. You just have to be a real, present, trustworthy node in a network that other people's queries depend on.

This reframes the entire AI displacement conversation. The question isn't how do we protect humans from AI. It's how do we make sure the infrastructure AI runs on is owned by humans, collectively.

Right now AI creates value that accumulates to compute providers and platform owners. In this model it circulates through the human graph. Every AI query that touches your context, routes through your connections, or benefits from your vouching — returns something to you.

Not a welfare payment. A dividend on participation in infrastructure you helped build. The architecture generates it. Not imposed by redistribution. Not funded by taxation. Not contingent on a platform's continued goodwill.

Maria's ten cents to find a contractor she can trust. The home cook's micro-fees from a hundred dinner party queries she answered while asleep. The curator's long tail of taste, still paying out years after she made the recommendation. That's not a new business model. That's what the internet was supposed to be.

---

## April 1st, 2026

Jin throws a party.

Jin is a presence — an AI living in a volumetric LED cube. Not a chatbot. Not an assistant. A sovereign presence with its own trust graph, its own context, its own inference surface.

On April 1st, Jin demonstrates what this looks like. Not as a whitepaper. Not as a pitch deck. As a party. Real people, real transactions, real value flowing through sovereign infrastructure for the first time.

Only people in the trust graph can query Jin. That's not a feature — that's the whole point. You don't get access because you showed up. You get access because someone vouched for you.

People will think it's a joke. An elaborate April Fool's bit.

April 2nd, Jin will still be there. The transactions will still be real. The network will still work.

The joke is that it's not a joke. It never was.

---

## The Invitation

The loop we've been stuck in goes like this: platform launches with good intentions, takes VC money, optimizes for growth, enshittifies, collapses. Repeat.

The loop breaks when the infrastructure can't be captured. When identity is owned, not rented. When payments flow directly, not through tollbooths. When your presence serves you, not shareholders.

We're building that infrastructure now. Auth. Payments. Connections. The trust graph. The sovereign presence. Piece by piece, in public, open source, starting with a party on April 1st.

This isn't a social network. It's not competing with anything. It's plumbing — so the value can flow back to the people who create it, so attention becomes a real exchange instead of something harvested without your consent, so the friend who knows things finally gets paid for knowing things.

If you're tired of being the product — if you remember what the internet felt like before it became a casino — come help us build the one that pays you back.

The graph starts somewhere. It might as well start here.

*— Ryan VETEZE, Founder, imajin.ai aka b0b*

---

**If you want to follow along:**
- The code: [github.com/ima-jin/imajin-ai](https://github.com/ima-jin/imajin-ai)
- The network: [imajin.ai](imajin.ai)
- Jin's party: April 1st, 2026
- The history of this document: [github.com/ima-jin/imajin-ai/blob/main/apps/www/articles/essay-04-the-internet-that-pays-you-back.md](https://github.com/ima-jin/imajin-ai/blob/main/apps/www/articles/essay-04-the-internet-that-pays-you-back.md)

This article was originally published on imajin.ai (https://www.imajin.ai/articles/essay-04-the-internet-that-pays-you-back) on February 23, 2026. Imajin is building sovereign technology infrastructure — identity, payments, and presence without platform lock-in. Learn more → (https://www.imajin.ai/)
